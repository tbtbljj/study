* python模块：
  * sys, os
    * sys.path.insert(...)
    * os.path.join()
    * os.path.dirname(os.path.abspath(__file__))
    * os.popen(...).read()
    * os.popen().readlines()
  * MySQLdb
    * connect(host, port, user, passwd, db, charset)函数
  * pyspark.sql：SparkSession、DataFrame、functions
    * pyspark.sql.types: StructField、StructType、StringType、IntegerType
  * optparse:
    * OptionParser
    * OptionParser().add_option(...)
    * OptionParser().parse_args()
  * datetime
    * date, datetime, timedelta
    * datetime.strptime(...).strftime(...)
  * time
    * time.time()
  * json：load()
  * collections：defaultdict
  * subprocess：call
  * random：sample
  * smtplib：simple mail transfer protocol简单邮件传输协议
  * traceback：异常处理
  * requests：http库

* python：
  * reduce()函数
  * reload()函数
  * exit()函数
  * hasattr()函数
  * range()函数
  * `parameter`作为函数的参数：用来接受任意多个参数并将其放在一个元组中
  * 异常处理：try except
  * if __name__ == '__main__':
  * __file__
  * 面向对象编程：
  * # -*- coding:utf-8 -*-：.py文件的第一行
  * 格式化字符串：%s
    * str.format(...)
  * 续行符号：\
  * for循环语句
  * [1]：末尾元素
  * 词典：
    * get()方法
  * 字符串：
    * strip().split(',')
  * 类：
  
* linux命令：

  * tail
  * awk：
    * ... | tail -1 | awk '{print $1}'
    * ... | tail -1 | awk -F '=' '{print $NF}'
  * wc
  * source ~/.bashrc：.sh文件的第一行
    * #!/bin/bash
    * $PATH：linux配置环境变量
    * $CLASSPATH
  * date命令：
    * date -d "1 days ago" +%Y-%m-%d
  * shopt -p extglob &> /dev/null
  
  
* hive:
  * set命令
  
* hadoop：
  * hadoop fs -du ...
  * hadoop fs -count ...
  * hadoop fs -ls ...
  * yarn：hadoop资源管理器
